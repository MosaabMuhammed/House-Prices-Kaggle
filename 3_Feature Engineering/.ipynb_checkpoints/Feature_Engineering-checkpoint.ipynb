{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T16:29:44.057464Z",
     "start_time": "2019-10-05T16:29:44.053445Z"
    }
   },
   "source": [
    "<center style='font-size:40px'><b>Feature Engineering</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview:\n",
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:40.719674Z",
     "start_time": "2019-10-10T16:47:40.710489Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from util import *\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 1000\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:41.875573Z",
     "start_time": "2019-10-10T16:47:40.721660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 77 \u001b[0m columns.\n",
      "~> [test ] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 76 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../2_Data Preprocessing/output/train_processed.csv')\n",
    "test  = pd.read_csv('../2_Data Preprocessing/output/test_processed.csv')\n",
    "\n",
    "\n",
    "shape(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:41.917481Z",
     "start_time": "2019-10-10T16:47:41.879443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [traintest] has \u001b[5m\u001b[7m\u001b[34m 2,919 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 77 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test together to apply the changes.\n",
    "traintest     = pd.concat([train, test], axis=0)\n",
    "train_ids     = train.Id\n",
    "train_labels  = train.SalePrice\n",
    "test_ids      = test.Id\n",
    "\n",
    "shape(traintest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T16:36:25.123264Z",
     "start_time": "2019-10-05T16:36:25.110563Z"
    }
   },
   "source": [
    "# Feature Generation: \n",
    "## Categorical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:42.085232Z",
     "start_time": "2019-10-10T16:47:41.919453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some utility function:\n",
    "def save_or_load(name):\n",
    "    # See if list colums is there or not.\n",
    "    if os.path.isfile(f'./{name}.pkl'):\n",
    "        with open(f'{name}.pkl', 'rb') as f: \n",
    "            list_cols = pickle.load(f)\n",
    "    else:\n",
    "        # Select only the list colums.\n",
    "        list_cols = [col for col in train.columns if col.startswith(name)]\n",
    "\n",
    "        # Save the list colums to later use.\n",
    "        with open(f'{name}.pkl', 'wb') as f:\n",
    "            pickle.dump(list_cols, f)\n",
    "    return list_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:42.209434Z",
     "start_time": "2019-10-10T16:47:42.090367Z"
    }
   },
   "outputs": [],
   "source": [
    "ord_cols  = ['LandSlope', 'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtExposure', \n",
    "             'BsmtFinType1', 'BsmtCond', 'BsmtQual', 'BsmtFinType2', 'HeatingQC', 'Electrical', \n",
    "             'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'KitchenQual', 'TotRmsAbvGrd', 'Functional',\n",
    "             'Fireplaces', 'FireplaceQu', 'GarageFinish', 'GarageCars', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
    "             'PoolQC', 'BedroomAbvGr', 'KitchenAbvGr']\n",
    "cat_cols  = ['MSSubClass', 'MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', \n",
    "            'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "            'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'GarageType', 'MiscFeature', 'SaleType', \n",
    "             'SaleCondition', 'HouseStyle', 'Fence', 'CentralAir']\n",
    "num_cols  = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "            '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "            'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
    "date_cols = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold', 'YrSold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:43.263991Z",
     "start_time": "2019-10-10T16:47:42.213971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 367 \u001b[0m columns.\n",
      "~> [test ] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 351 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "for var in list(ord_cols+cat_cols):\n",
    "    train = pd.concat([train, pd.get_dummies(train[var], prefix=f'onehot_{var}', prefix_sep='_', drop_first=True)], axis=1)\n",
    "    test  = pd.concat([test, pd.get_dummies(test[var], prefix=f'onehot_{var}', prefix_sep='_', drop_first=True)], axis=1)\n",
    "\n",
    "shape(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:43.322575Z",
     "start_time": "2019-10-10T16:47:43.266194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 337 \u001b[0m columns.\n",
      "~> [test ] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 336 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "# Align all the columns in train data with test data.\n",
    "train_labels       = train.SalePrice\n",
    "train, test        = train.align(test, join='inner', axis=1)\n",
    "train['SalePrice'] = train_labels\n",
    "\n",
    "shape(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see after aligning the train and test datasets, there are number of columns dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:43.364620Z",
     "start_time": "2019-10-10T16:47:43.332091Z"
    }
   },
   "outputs": [],
   "source": [
    "onehot_cols = save_or_load('onehot_cols')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:29:43.971792Z",
     "start_time": "2019-10-10T14:29:43.958441Z"
    }
   },
   "source": [
    "### Frequency Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:46.134948Z",
     "start_time": "2019-10-10T16:47:43.367961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 390 \u001b[0m columns.\n",
      "~> [test ] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 389 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "for col in list(cat_cols+ord_cols):\n",
    "    encoding             = traintest[col].value_counts(normalize=True)\n",
    "    train[f'freq_{col}'] = train[col].apply(lambda x: encoding[x])\n",
    "    test[f'freq_{col}']  = test[col].apply(lambda x: encoding[x])\n",
    "\n",
    "shape(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:46.144057Z",
     "start_time": "2019-10-10T16:47:46.137155Z"
    }
   },
   "outputs": [],
   "source": [
    "freq_cols = save_or_load('freq_cols')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T15:05:25.780371Z",
     "start_time": "2019-10-10T15:05:25.771323Z"
    }
   },
   "source": [
    "### Target Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:52.340129Z",
     "start_time": "2019-10-10T16:47:46.145475Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in list(cat_cols+ord_cols):\n",
    "    means   = train.groupby(col).SalePrice.mean()\n",
    "    stds    = train.groupby(col).SalePrice.std()\n",
    "    skews   = train.groupby(col).SalePrice.skew()\n",
    "    counts  = train.groupby(col).SalePrice.count()\n",
    "    medians = train.groupby(col).SalePrice.median()\n",
    "    mins    = train.groupby(col).SalePrice.min()\n",
    "    maxs    = train.groupby(col).SalePrice.max()\n",
    "    \n",
    "    for stat in [means, stds, skews, medians, mins, maxs]:\n",
    "        train[f'target_enc_{var2str(stat)}_{col}'] = train[col].map(stat)\n",
    "        test[f'target_enc_{var2str(stat)}_{col}']  = test[col].map(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:52.346130Z",
     "start_time": "2019-10-10T16:47:52.341888Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# save or load the target encoded columns' names.\n",
    "target_enc_cols = save_or_load('target_enc_cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:52.503432Z",
     "start_time": "2019-10-10T16:47:52.348383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 708 \u001b[0m columns.\n",
      "~> [test ] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 707 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "shape(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "    <p style='font-size:20px;font-weight:bold'>Note:<p>\n",
    "    <p style='font-size:16px'>We can see that the number of columns increases as we go along. <br>In the next notebook, we'll apply some feature selection techniques to get rid of the redundant features.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## Numerical Features:\n",
    "### Log1p / Sqrt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:52.685442Z",
     "start_time": "2019-10-10T16:47:52.505709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 742 \u001b[0m columns.\n",
      "~> [test ] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 741 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "for col in num_cols:\n",
    "    train[f'log_{col}'] = np.log1p(train[col])\n",
    "    train[f'sqrt_{col}'] = np.sqrt(train[col])\n",
    "    \n",
    "    test[f'log_{col}'] = np.log1p(test[col])\n",
    "    test[f'sqrt_{col}'] = np.sqrt(test[col])\n",
    "\n",
    "# See the shape of both datsets.\n",
    "shape(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the name of the columns for later use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:47:52.696692Z",
     "start_time": "2019-10-10T16:47:52.687873Z"
    }
   },
   "outputs": [],
   "source": [
    "# save or load the log/sqrt columns' names.\n",
    "log_cols = save_or_load('log_cols')\n",
    "sqrt_cols = save_or_load('sqrt_cols')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:04:54.873893Z",
     "start_time": "2019-10-10T17:04:54.710342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> [poly_train] has \u001b[5m\u001b[7m\u001b[34m 1,460 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 1,139 \u001b[0m columns.\n",
      "~> [poly_test] has \u001b[5m\u001b[7m\u001b[34m 1,459 \u001b[0m rows, and \u001b[5m\u001b[7m\u001b[34m 1,139 \u001b[0m columns.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_transformer = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly_transformer.fit(train[num_cols])\n",
    "\n",
    "poly_train = poly_transformer.transform(train[num_cols])\n",
    "poly_test  = poly_transformer.transform(test[num_cols])\n",
    "\n",
    "shape(poly_train, poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
